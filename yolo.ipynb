{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c84ea-42eb-46c6-aab1-f508760095e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a59ae5-de08-442f-847f-699d78c34192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.conda.is_avilable()\n",
    "torch.conda_device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57701115-22cd-41ab-beef-de4c9447cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 13.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0785fc07-3390-4b93-a0d6-842ba3cc5a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('media/detection_image.jpg')\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf39ed1-04fd-4144-aa85-9a92ed46d00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 7 persons, 1 bicycle, 1 car, 2 buss, 1 truck, 2 traffic lights, 29.3ms\n",
      "Speed: 2.4ms preprocess, 29.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detections:  tensor([5., 0., 0., 0., 0., 0., 5., 1., 9., 7., 2., 9., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# run YOLO model prediction\n",
    "results = model.predict(source=image, save= False, imgsz=640, conf=0.25, device='cpu')\n",
    "print(\"Detections: \",results[0].boxes.cls)\n",
    "\n",
    "#parse results\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy #(x1,y1,x2,y2)\n",
    "    scores = result.boxes.conf\n",
    "    class_ids = result.boxes.cls\n",
    "\n",
    "    for box, score, class_id in zip(boxes,scores,class_ids):\n",
    "        x1,y1,x2,y2 = map(int, box)\n",
    "        label = model.names[int(class_id)]\n",
    "        confidence = float(score)\n",
    "\n",
    "        #Draw rectangle\n",
    "        cv2.rectangle(image, (x1,y1),(x2,y2),(0,255,0),2)\n",
    "        #put label\n",
    "        cv2.putText(image, f'{label} {confidence: .2f}',(x1,y1 - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
    "\n",
    "#show the image\n",
    "cv2.imshow('YOLOV8 Detection', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cda2af23-bf5e-49a5-97ed-1b0380f85c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.154 ðŸš€ Python-3.12.7 torch-2.7.1 CPU (Apple M4 Pro)\n",
      "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.57...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.5s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (0.6s)\n",
      "Results saved to \u001b[1m/Users/aspaaur/Documents/Personal/AI/ml-ai-projects/deep-learning/computer-vision/yolo-detection\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8n.onnx'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# Load the YOLOv8 model (can be 'yolo8n.pt', 'yolo8s.pt', or your custom model)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "#export the model ONXX\n",
    "model.export(format='onnx',opset=12,simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266e581-3999-4b83-a106-99b475a5e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromONNX('yolov8n.onnx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
